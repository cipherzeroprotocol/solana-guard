{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af465690",
   "metadata": {},
   "source": [
    "# Dusting Attack & Address Poisoning Analysis Notebook\n",
    "\n",
    "This notebook analyzes dusting attacks and address poisoning attempts on the Solana blockchain, particularly focusing on techniques documented by Chainalysis and other security researchers.\n",
    "\n",
    "## Overview\n",
    "\n",
    "### Dusting Attacks\n",
    "Dusting attacks involve sending tiny amounts of cryptocurrency to many addresses to break privacy by linking these addresses together when the dust is moved.\n",
    "\n",
    "### Address Poisoning\n",
    "Address poisoning is a technique where attackers create addresses visually similar to a victim's frequent contacts, then send small transactions to make their address appear in the transaction history, hoping the victim will mistakenly send funds to the malicious address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0544474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utils modules imported from data_collection.utils\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Add project root to Python path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '../..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "# Import SolanaGuard modules\n",
    "from data_collection.collectors.helius_collector import HeliusCollector\n",
    "from data_collection.collectors.range_collector import RangeCollector\n",
    "\n",
    "# Try to import utils - similar approach as in mixer_detection notebook\n",
    "try:\n",
    "    from utils.address_utils import detect_dusting_and_poisoning\n",
    "    print(\"Utils modules imported successfully\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        from data_collection.utils.address_utils import detect_dusting_and_poisoning\n",
    "        print(\"Utils modules imported from data_collection.utils\")\n",
    "    except ImportError:\n",
    "        # Define placeholder function if module can't be found\n",
    "        print(\"WARNING: Could not import address_utils module. Using placeholder functions.\")\n",
    "        \n",
    "        def detect_dusting_and_poisoning(address, token_transfers, dusting_attacks, address_poisoning):\n",
    "            \"\"\"Placeholder function for detecting dusting and poisoning attacks.\"\"\"\n",
    "            return {\n",
    "                \"address\": address,\n",
    "                \"dusting_detected\": not dusting_attacks.empty if hasattr(dusting_attacks, 'empty') else bool(dusting_attacks),\n",
    "                \"poisoning_detected\": not address_poisoning.empty if hasattr(address_poisoning, 'empty') else bool(address_poisoning),\n",
    "                \"dusting_attacks\": dusting_attacks,\n",
    "                \"poisoning_attempts\": address_poisoning\n",
    "            }\n",
    "\n",
    "# Configure plot style\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625d41b7",
   "metadata": {},
   "source": [
    "## Initialize API Collectors\n",
    "\n",
    "First, we initialize the necessary API collectors to gather data from various sources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0de38adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:06,385 - helius_collector - INFO - Initialized Helius collector\n",
      "2025-04-24 23:33:06,387 - range_collector - INFO - Initialized Range collector\n",
      "2025-04-24 23:33:06,387 - range_collector - INFO - Initialized Range collector\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collectors initialized successfully\n"
     ]
    }
   ],
   "source": [
    "# Initialize collectors\n",
    "helius = HeliusCollector()\n",
    "range_api = RangeCollector()\n",
    "\n",
    "print(\"Collectors initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec58d788",
   "metadata": {},
   "source": [
    "## Identify Target Addresses\n",
    "\n",
    "Let's identify addresses that might be targets of dusting attacks or address poisoning. We'll look at high-value wallets and frequent traders:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e1a65090",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:06,406 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 200)\n",
      "2025-04-24 23:33:06,407 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:06,407 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:06,529 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:06,541 - helius_collector - INFO - Analyzing token transfers for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "2025-04-24 23:33:06,542 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 200)\n",
      "2025-04-24 23:33:06,543 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:06,529 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:06,541 - helius_collector - INFO - Analyzing token transfers for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "2025-04-24 23:33:06,542 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 200)\n",
      "2025-04-24 23:33:06,543 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing address: Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "Error fetching transaction history: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:06,656 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:06,658 - helius_collector - INFO - Detecting dusting attacks for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (threshold: 0.1 USD)\n",
      "2025-04-24 23:33:06,659 - helius_collector - INFO - Analyzing token transfers for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "2025-04-24 23:33:06,661 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 1000)\n",
      "2025-04-24 23:33:06,662 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:06,658 - helius_collector - INFO - Detecting dusting attacks for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (threshold: 0.1 USD)\n",
      "2025-04-24 23:33:06,659 - helius_collector - INFO - Analyzing token transfers for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "2025-04-24 23:33:06,661 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 1000)\n",
      "2025-04-24 23:33:06,662 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:06,859 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:06,859 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analyzing token transfers: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:06,861 - helius_collector - INFO - Detecting address poisoning for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "2025-04-24 23:33:06,862 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 1000)\n",
      "2025-04-24 23:33:06,863 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:06,862 - helius_collector - INFO - Fetching transaction history for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 1000)\n",
      "2025-04-24 23:33:06,863 - helius_collector - INFO - Getting signatures for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD (limit: 100)\n",
      "2025-04-24 23:33:07,052 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:07,052 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting dusting attacks: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:07,054 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 200)\n",
      "2025-04-24 23:33:07,055 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n",
      "2025-04-24 23:33:07,055 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n",
      "2025-04-24 23:33:07,258 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:07,258 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting address poisoning: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "\n",
      "Analyzing address: dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:07,260 - helius_collector - INFO - Analyzing token transfers for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "2025-04-24 23:33:07,261 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 200)\n",
      "2025-04-24 23:33:07,261 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n",
      "2025-04-24 23:33:07,261 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 200)\n",
      "2025-04-24 23:33:07,261 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching transaction history: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:07,481 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:07,484 - helius_collector - INFO - Detecting dusting attacks for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (threshold: 0.1 USD)\n",
      "2025-04-24 23:33:07,485 - helius_collector - INFO - Analyzing token transfers for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "2025-04-24 23:33:07,486 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 1000)\n",
      "2025-04-24 23:33:07,486 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n",
      "2025-04-24 23:33:07,484 - helius_collector - INFO - Detecting dusting attacks for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (threshold: 0.1 USD)\n",
      "2025-04-24 23:33:07,485 - helius_collector - INFO - Analyzing token transfers for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "2025-04-24 23:33:07,486 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 1000)\n",
      "2025-04-24 23:33:07,486 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n",
      "2025-04-24 23:33:07,662 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:07,663 - helius_collector - INFO - Detecting address poisoning for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "2025-04-24 23:33:07,664 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 1000)\n",
      "2025-04-24 23:33:07,666 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n",
      "2025-04-24 23:33:07,662 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:07,663 - helius_collector - INFO - Detecting address poisoning for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "2025-04-24 23:33:07,664 - helius_collector - INFO - Fetching transaction history for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 1000)\n",
      "2025-04-24 23:33:07,666 - helius_collector - INFO - Getting signatures for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH (limit: 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analyzing token transfers: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "Error detecting dusting attacks: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:07,854 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:07,856 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 200)\n",
      "2025-04-24 23:33:07,857 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:07,856 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 200)\n",
      "2025-04-24 23:33:07,857 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:08,045 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:08,045 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting address poisoning: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "\n",
      "Analyzing address: AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:08,046 - helius_collector - INFO - Analyzing token transfers for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n",
      "2025-04-24 23:33:08,047 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 200)\n",
      "2025-04-24 23:33:08,048 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:08,047 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 200)\n",
      "2025-04-24 23:33:08,048 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:08,249 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:08,249 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching transaction history: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:08,250 - helius_collector - INFO - Detecting dusting attacks for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (threshold: 0.1 USD)\n",
      "2025-04-24 23:33:08,251 - helius_collector - INFO - Analyzing token transfers for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n",
      "2025-04-24 23:33:08,253 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 1000)\n",
      "2025-04-24 23:33:08,253 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:08,251 - helius_collector - INFO - Analyzing token transfers for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n",
      "2025-04-24 23:33:08,253 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 1000)\n",
      "2025-04-24 23:33:08,253 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:08,447 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n",
      "2025-04-24 23:33:08,447 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error analyzing token transfers: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:08,449 - helius_collector - INFO - Detecting address poisoning for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n",
      "2025-04-24 23:33:08,450 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 1000)\n",
      "2025-04-24 23:33:08,451 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n",
      "2025-04-24 23:33:08,450 - helius_collector - INFO - Fetching transaction history for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 1000)\n",
      "2025-04-24 23:33:08,451 - helius_collector - INFO - Getting signatures for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8 (limit: 100)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting dusting attacks: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-24 23:33:08,655 - helius_collector - ERROR - Failed to make RPC request: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error detecting address poisoning: Request failed: 401 Client Error: Unauthorized for url: https://mainnet.helius-rpc.com/?api-key=None\n"
     ]
    }
   ],
   "source": [
    "# Real Solana addresses to analyze for dusting attacks\n",
    "target_addresses = [\n",
    "    \"Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\", # Prominent NFT collector address\n",
    "    \"dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\",  # High-value DeFi user\n",
    "    \"AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\"   # Exchange hot wallet\n",
    "]\n",
    "\n",
    "# Function to analyze an address for dusting and poisoning\n",
    "def analyze_address_attacks(address):\n",
    "    print(f\"\\nAnalyzing address: {address}\")\n",
    "    \n",
    "    # Step 1: Get transaction history\n",
    "    try:\n",
    "        tx_history = helius.fetch_transaction_history(address, limit=200)\n",
    "        print(f\"Fetched {len(tx_history)} transactions\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching transaction history: {e}\")\n",
    "        tx_history = pd.DataFrame()\n",
    "    \n",
    "    # Step 2: Get token transfers\n",
    "    try:\n",
    "        token_transfers = helius.analyze_token_transfers(address, limit=200)\n",
    "        print(f\"Fetched {len(token_transfers)} token transfers\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing token transfers: {e}\")\n",
    "        token_transfers = pd.DataFrame()\n",
    "    \n",
    "    # Step 3: Detect dusting attacks\n",
    "    try:\n",
    "        dusting_attacks = helius.detect_dusting_attacks(address)\n",
    "        print(f\"Detected {len(dusting_attacks)} potential dusting attacks\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting dusting attacks: {e}\")\n",
    "        dusting_attacks = pd.DataFrame()\n",
    "    \n",
    "    # Step 4: Detect address poisoning\n",
    "    try:\n",
    "        address_poisoning = helius.detect_address_poisoning(address)\n",
    "        print(f\"Detected {len(address_poisoning)} potential address poisoning attempts\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error detecting address poisoning: {e}\")\n",
    "        address_poisoning = pd.DataFrame()\n",
    "    \n",
    "    results = {\n",
    "        \"address\": address,\n",
    "        \"tx_history\": tx_history,\n",
    "        \"token_transfers\": token_transfers,\n",
    "        \"dusting_attacks\": dusting_attacks,\n",
    "        \"address_poisoning\": address_poisoning\n",
    "    }\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze each address\n",
    "analysis_results = {}\n",
    "for address in target_addresses:\n",
    "    analysis_results[address] = analyze_address_attacks(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d7be8e0",
   "metadata": {},
   "source": [
    "## Analyze Dusting Attacks\n",
    "\n",
    "Now, let's analyze the detected dusting attacks in more detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "442b63fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No dusting attacks detected for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "No dusting attacks detected for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "No dusting attacks detected for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze dusting attacks\n",
    "def analyze_dusting_patterns(address, dusting_data):\n",
    "    if dusting_data.empty:\n",
    "        print(f\"No dusting attacks detected for {address}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nAnalyzing dusting attacks for {address}:\")\n",
    "    print(f\"Found {len(dusting_data)} suspicious dust transfers\")\n",
    "    \n",
    "    # Analyze dust by token\n",
    "    if \"mint\" in dusting_data.columns:\n",
    "        dust_by_token = dusting_data[\"mint\"].value_counts().reset_index()\n",
    "        dust_by_token.columns = [\"mint\", \"count\"]\n",
    "        \n",
    "        print(\"\\nDust by token:\")\n",
    "        for _, row in dust_by_token.iterrows():\n",
    "            print(f\"- {row['mint']}: {row['count']} dusting transactions\")\n",
    "    \n",
    "    # Analyze dust amount distribution\n",
    "    if \"amount\" in dusting_data.columns:\n",
    "        print(\"\\nDust amount statistics:\")\n",
    "        print(f\"- Min amount: {dusting_data['amount'].min()}\")\n",
    "        print(f\"- Max amount: {dusting_data['amount'].max()}\")\n",
    "        print(f\"- Mean amount: {dusting_data['amount'].mean()}\")\n",
    "        \n",
    "        # Plot dust amount distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(dusting_data[\"amount\"], kde=True)\n",
    "        plt.title(f\"Dust Amount Distribution for {address}\")\n",
    "        plt.xlabel(\"Amount\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Analyze temporal patterns\n",
    "    if \"block_time\" in dusting_data.columns:\n",
    "        dusting_data[\"datetime\"] = pd.to_datetime(dusting_data[\"block_time\"], unit=\"s\")\n",
    "        dusting_data = dusting_data.sort_values(\"datetime\")\n",
    "        \n",
    "        # Calculate intervals between dust transfers\n",
    "        dusting_data[\"time_diff\"] = dusting_data[\"datetime\"].diff().dt.total_seconds()\n",
    "        \n",
    "        print(\"\\nTemporal patterns:\")\n",
    "        print(f\"- First dust: {dusting_data['datetime'].min()}\")\n",
    "        print(f\"- Last dust: {dusting_data['datetime'].max()}\")\n",
    "        print(f\"- Duration: {(dusting_data['datetime'].max() - dusting_data['datetime'].min()).total_seconds() / 3600:.2f} hours\")\n",
    "        \n",
    "        # Check for regular intervals (possible automated dusting)\n",
    "        if len(dusting_data) > 3:\n",
    "            time_diffs = dusting_data[\"time_diff\"].dropna()\n",
    "            if len(time_diffs) > 0:\n",
    "                mean_diff = time_diffs.mean()\n",
    "                std_diff = time_diffs.std()\n",
    "                cv = std_diff / mean_diff if mean_diff > 0 else 0\n",
    "                \n",
    "                print(f\"- Mean interval: {mean_diff:.2f} seconds\")\n",
    "                print(f\"- Interval std dev: {std_diff:.2f} seconds\")\n",
    "                print(f\"- Coefficient of variation: {cv:.4f}\")\n",
    "                \n",
    "                # Low CV suggests regular intervals (automated)\n",
    "                if cv < 0.3 and len(time_diffs) > 5:\n",
    "                    print(\"⚠️ Regular intervals detected - likely automated dusting attack\")\n",
    "        \n",
    "        # Plot dust over time\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.scatter(dusting_data[\"datetime\"], dusting_data[\"amount\"], alpha=0.7)\n",
    "        plt.title(f\"Dust Transfers Over Time for {address}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Amount\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        \"address\": address,\n",
    "        \"dust_count\": len(dusting_data),\n",
    "        \"dust_by_token\": dust_by_token.to_dict(\"records\") if \"mint\" in dusting_data.columns else [],\n",
    "        \"amount_stats\": {\n",
    "            \"min\": dusting_data[\"amount\"].min() if \"amount\" in dusting_data.columns else 0,\n",
    "            \"max\": dusting_data[\"amount\"].max() if \"amount\" in dusting_data.columns else 0,\n",
    "            \"mean\": dusting_data[\"amount\"].mean() if \"amount\" in dusting_data.columns else 0\n",
    "        },\n",
    "        \"temporal_stats\": {\n",
    "            \"first_dust\": dusting_data[\"datetime\"].min() if \"block_time\" in dusting_data.columns else None,\n",
    "            \"last_dust\": dusting_data[\"datetime\"].max() if \"block_time\" in dusting_data.columns else None,\n",
    "            \"is_automated\": (cv < 0.3 and len(time_diffs) > 5) if \"block_time\" in dusting_data.columns and len(dusting_data) > 3 else False\n",
    "        } if \"block_time\" in dusting_data.columns else {}\n",
    "    }\n",
    "\n",
    "# Analyze dusting patterns for each address\n",
    "dusting_analyses = {}\n",
    "for address, data in analysis_results.items():\n",
    "    dusting_analyses[address] = analyze_dusting_patterns(address, data[\"dusting_attacks\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e3329a",
   "metadata": {},
   "source": [
    "## Analyze Address Poisoning\n",
    "\n",
    "Now, let's analyze the detected address poisoning attempts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "57025546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No address poisoning detected for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
      "No address poisoning detected for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
      "No address poisoning detected for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n"
     ]
    }
   ],
   "source": [
    "# Function to analyze address poisoning\n",
    "def analyze_poisoning_patterns(address, poisoning_data):\n",
    "    if poisoning_data.empty:\n",
    "        print(f\"No address poisoning detected for {address}\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nAnalyzing address poisoning for {address}:\")\n",
    "    print(f\"Found {len(poisoning_data)} suspicious look-alike addresses\")\n",
    "    \n",
    "    # Analyze similarity scores\n",
    "    if \"similarity_score\" in poisoning_data.columns:\n",
    "        print(\"\\nSimilarity score statistics:\")\n",
    "        print(f\"- Min similarity: {poisoning_data['similarity_score'].min():.2f}\")\n",
    "        print(f\"- Max similarity: {poisoning_data['similarity_score'].max():.2f}\")\n",
    "        print(f\"- Mean similarity: {poisoning_data['similarity_score'].mean():.2f}\")\n",
    "        \n",
    "        # Plot similarity score distribution\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.histplot(poisoning_data[\"similarity_score\"], kde=True)\n",
    "        plt.title(f\"Address Similarity Score Distribution for {address}\")\n",
    "        plt.xlabel(\"Similarity Score\")\n",
    "        plt.ylabel(\"Frequency\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # List similar addresses and their similarity scores\n",
    "    if \"similar_address\" in poisoning_data.columns and \"similarity_score\" in poisoning_data.columns:\n",
    "        poisoning_data = poisoning_data.sort_values(\"similarity_score\", ascending=False)\n",
    "        \n",
    "        print(\"\\nTop similar addresses:\")\n",
    "        for i, (_, row) in enumerate(poisoning_data.head(10).iterrows()):\n",
    "            print(f\"- {row['similar_address']} (similarity: {row['similarity_score']:.2f})\")\n",
    "            \n",
    "            # Display address comparison\n",
    "            print(f\"  Original: {address}\")\n",
    "            print(f\"  Similar:  {row['similar_address']}\")\n",
    "            \n",
    "            # Visualize character differences\n",
    "            indicator = \"\"\n",
    "            for j in range(min(len(address), len(row['similar_address']))):\n",
    "                if address[j] == row['similar_address'][j]:\n",
    "                    indicator += \" \"\n",
    "                else:\n",
    "                    indicator += \"^\"\n",
    "            print(f\"           {indicator}\")\n",
    "    \n",
    "    # Analyze temporal patterns\n",
    "    if \"block_time\" in poisoning_data.columns:\n",
    "        poisoning_data[\"datetime\"] = pd.to_datetime(poisoning_data[\"block_time\"], unit=\"s\")\n",
    "        poisoning_data = poisoning_data.sort_values(\"datetime\")\n",
    "        \n",
    "        print(\"\\nTemporal patterns:\")\n",
    "        print(f\"- First poisoning attempt: {poisoning_data['datetime'].min()}\")\n",
    "        print(f\"- Last poisoning attempt: {poisoning_data['datetime'].max()}\")\n",
    "        print(f\"- Duration: {(poisoning_data['datetime'].max() - poisoning_data['datetime'].min()).total_seconds() / 3600:.2f} hours\")\n",
    "        \n",
    "        # Plot poisoning attempts over time\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.scatter(poisoning_data[\"datetime\"], poisoning_data[\"similarity_score\"] if \"similarity_score\" in poisoning_data.columns else [1] * len(poisoning_data), alpha=0.7)\n",
    "        plt.title(f\"Address Poisoning Attempts Over Time for {address}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Similarity Score\")\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return {\n",
    "        \"address\": address,\n",
    "        \"poisoning_count\": len(poisoning_data),\n",
    "        \"similar_addresses\": poisoning_data[\"similar_address\"].tolist() if \"similar_address\" in poisoning_data.columns else [],\n",
    "        \"similarity_stats\": {\n",
    "            \"min\": poisoning_data[\"similarity_score\"].min() if \"similarity_score\" in poisoning_data.columns else 0,\n",
    "            \"max\": poisoning_data[\"similarity_score\"].max() if \"similarity_score\" in poisoning_data.columns else 0,\n",
    "            \"mean\": poisoning_data[\"similarity_score\"].mean() if \"similarity_score\" in poisoning_data.columns else 0\n",
    "        } if \"similarity_score\" in poisoning_data.columns else {},\n",
    "        \"temporal_stats\": {\n",
    "            \"first_attempt\": poisoning_data[\"datetime\"].min() if \"block_time\" in poisoning_data.columns else None,\n",
    "            \"last_attempt\": poisoning_data[\"datetime\"].max() if \"block_time\" in poisoning_data.columns else None\n",
    "        } if \"block_time\" in poisoning_data.columns else {}\n",
    "    }\n",
    "\n",
    "# Analyze poisoning patterns for each address\n",
    "poisoning_analyses = {}\n",
    "for address, data in analysis_results.items():\n",
    "    poisoning_analyses[address] = analyze_poisoning_patterns(address, data[\"address_poisoning\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49123e29",
   "metadata": {},
   "source": [
    "## Combine Detection Results\n",
    "\n",
    "Let's combine our dusting and poisoning detection results for a comprehensive analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0348484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined analysis for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD:\n",
      "- Dusting detected: False\n",
      "- Poisoning detected: False\n",
      "\n",
      "Combined analysis for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH:\n",
      "- Dusting detected: False\n",
      "- Poisoning detected: False\n",
      "\n",
      "Combined analysis for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8:\n",
      "- Dusting detected: False\n",
      "- Poisoning detected: False\n"
     ]
    }
   ],
   "source": [
    "# Combine dusting and poisoning detection results\n",
    "for address, data in analysis_results.items():\n",
    "    # Use the utility function to combine detection results\n",
    "    combined_analysis = detect_dusting_and_poisoning(\n",
    "        address,\n",
    "        data[\"token_transfers\"],\n",
    "        data[\"dusting_attacks\"],\n",
    "        data[\"address_poisoning\"]\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nCombined analysis for {address}:\")\n",
    "    print(f\"- Dusting detected: {combined_analysis['dusting_detected']}\")\n",
    "    print(f\"- Poisoning detected: {combined_analysis['poisoning_detected']}\")\n",
    "    \n",
    "    # Show detailed attack information\n",
    "    if combined_analysis[\"dusting_detected\"]:\n",
    "        print(\"\\nDusting attacks:\")\n",
    "        for attack in combined_analysis[\"dusting_attacks\"][:3]:  # Show top 3\n",
    "            if isinstance(attack, dict) and \"type\" in attack:\n",
    "                print(f\"- {attack['type']}: {attack.get('count', 0)} instances\")\n",
    "            else:\n",
    "                print(f\"- Attack details: {attack}\")\n",
    "    \n",
    "    if combined_analysis[\"poisoning_detected\"]:\n",
    "        print(\"\\nPoisoning attempts:\")\n",
    "        for attempt in combined_analysis[\"poisoning_attempts\"][:3]:  # Show top 3\n",
    "            if isinstance(attempt, dict) and \"similar_address\" in attempt:\n",
    "                print(f\"- Similar address: {attempt['similar_address']} (score: {attempt.get('similarity_score', 0):.2f})\")\n",
    "            else:\n",
    "                print(f\"- Attempt details: {attempt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce5d48",
   "metadata": {},
   "source": [
    "## Identify Attack Patterns\n",
    "\n",
    "Let's identify common patterns across the attacks we've detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "11bfc547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Attack Patterns:\n",
      "Dusting: 0 attacks affecting 0 addresses\n",
      "Poisoning: 0 attempts affecting 0 addresses\n"
     ]
    }
   ],
   "source": [
    "# Identify common attack patterns\n",
    "def identify_attack_patterns():\n",
    "    # Combine all dusting attacks\n",
    "    all_dusting = []\n",
    "    for address, data in analysis_results.items():\n",
    "        if not data[\"dusting_attacks\"].empty:\n",
    "            dusting = data[\"dusting_attacks\"].copy()\n",
    "            dusting[\"target_address\"] = address\n",
    "            all_dusting.append(dusting)\n",
    "    \n",
    "    dusting_df = pd.concat(all_dusting) if all_dusting else pd.DataFrame()\n",
    "    \n",
    "    # Combine all poisoning attempts\n",
    "    all_poisoning = []\n",
    "    for address, data in analysis_results.items():\n",
    "        if not data[\"address_poisoning\"].empty:\n",
    "            poisoning = data[\"address_poisoning\"].copy()\n",
    "            poisoning[\"target_address\"] = address\n",
    "            all_poisoning.append(poisoning)\n",
    "    \n",
    "    poisoning_df = pd.concat(all_poisoning) if all_poisoning else pd.DataFrame()\n",
    "    \n",
    "    # Analyze common patterns\n",
    "    patterns = {\n",
    "        \"dusting\": {\n",
    "            \"total_count\": len(dusting_df),\n",
    "            \"targets_affected\": dusting_df[\"target_address\"].nunique() if not dusting_df.empty else 0,\n",
    "            \"patterns\": []\n",
    "        },\n",
    "        \"poisoning\": {\n",
    "            \"total_count\": len(poisoning_df),\n",
    "            \"targets_affected\": poisoning_df[\"target_address\"].nunique() if not poisoning_df.empty else 0,\n",
    "            \"patterns\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Identify dusting patterns\n",
    "    if not dusting_df.empty and \"mint\" in dusting_df.columns:\n",
    "        # Common tokens used for dusting\n",
    "        common_dust_tokens = dusting_df[\"mint\"].value_counts().reset_index()\n",
    "        common_dust_tokens.columns = [\"mint\", \"count\"]\n",
    "        \n",
    "        patterns[\"dusting\"][\"common_tokens\"] = common_dust_tokens.to_dict(\"records\")\n",
    "        \n",
    "        # Typical dust amounts\n",
    "        if \"amount\" in dusting_df.columns:\n",
    "            patterns[\"dusting\"][\"amount_stats\"] = {\n",
    "                \"min\": dusting_df[\"amount\"].min(),\n",
    "                \"max\": dusting_df[\"amount\"].max(),\n",
    "                \"mean\": dusting_df[\"amount\"].mean()\n",
    "            }\n",
    "            \n",
    "            # Calculate common dust amounts (cluster analysis)\n",
    "            from sklearn.cluster import KMeans\n",
    "            \n",
    "            amounts = dusting_df[\"amount\"].values.reshape(-1, 1)\n",
    "            if len(amounts) > 5:  # Need enough samples for clustering\n",
    "                kmeans = KMeans(n_clusters=min(5, len(amounts)), random_state=0).fit(amounts)\n",
    "                \n",
    "                # Get cluster centers and counts\n",
    "                centers = kmeans.cluster_centers_.flatten()\n",
    "                labels = kmeans.labels_\n",
    "                cluster_counts = np.bincount(labels)\n",
    "                \n",
    "                clusters = []\n",
    "                for i in range(len(centers)):\n",
    "                    clusters.append({\n",
    "                        \"amount\": centers[i],\n",
    "                        \"count\": int(cluster_counts[i])\n",
    "                    })\n",
    "                \n",
    "                patterns[\"dusting\"][\"amount_clusters\"] = clusters\n",
    "        \n",
    "        # Check for coordinated attacks (same block time)\n",
    "        if \"block_time\" in dusting_df.columns:\n",
    "            block_time_counts = dusting_df[\"block_time\"].value_counts()\n",
    "            coordinated_times = block_time_counts[block_time_counts > 1].index.tolist()\n",
    "            \n",
    "            if coordinated_times:\n",
    "                coordinated_attacks = []\n",
    "                \n",
    "                for time in coordinated_times:\n",
    "                    attacks = dusting_df[dusting_df[\"block_time\"] == time]\n",
    "                    \n",
    "                    coordinated_attacks.append({\n",
    "                        \"time\": pd.to_datetime(time, unit=\"s\"),\n",
    "                        \"target_count\": attacks[\"target_address\"].nunique(),\n",
    "                        \"attack_count\": len(attacks)\n",
    "                    })\n",
    "                \n",
    "                patterns[\"dusting\"][\"coordinated_attacks\"] = coordinated_attacks\n",
    "    \n",
    "    # Identify poisoning patterns\n",
    "    if not poisoning_df.empty and \"similar_address\" in poisoning_df.columns:\n",
    "        # Check for reused poisoning addresses\n",
    "        address_counts = poisoning_df[\"similar_address\"].value_counts().reset_index()\n",
    "        address_counts.columns = [\"address\", \"count\"]\n",
    "        \n",
    "        reused_addresses = address_counts[address_counts[\"count\"] > 1]\n",
    "        patterns[\"poisoning\"][\"reused_addresses\"] = reused_addresses.to_dict(\"records\")\n",
    "        \n",
    "        # Check for temporal patterns\n",
    "        if \"block_time\" in poisoning_df.columns:\n",
    "            poisoning_df[\"datetime\"] = pd.to_datetime(poisoning_df[\"block_time\"], unit=\"s\")\n",
    "            poisoning_df = poisoning_df.sort_values(\"datetime\")\n",
    "            \n",
    "            # Group attacks by date\n",
    "            poisoning_df[\"date\"] = poisoning_df[\"datetime\"].dt.date\n",
    "            daily_attacks = poisoning_df.groupby(\"date\").size().reset_index()\n",
    "            daily_attacks.columns = [\"date\", \"count\"]\n",
    "            \n",
    "            patterns[\"poisoning\"][\"daily_attacks\"] = daily_attacks.to_dict(\"records\")\n",
    "            \n",
    "            # Check for coordinated attacks (same block time)\n",
    "            block_time_counts = poisoning_df[\"block_time\"].value_counts()\n",
    "            coordinated_times = block_time_counts[block_time_counts > 1].index.tolist()\n",
    "            \n",
    "            if coordinated_times:\n",
    "                coordinated_attacks = []\n",
    "                \n",
    "                for time in coordinated_times:\n",
    "                    attacks = poisoning_df[poisoning_df[\"block_time\"] == time]\n",
    "                    \n",
    "                    coordinated_attacks.append({\n",
    "                        \"time\": pd.to_datetime(time, unit=\"s\"),\n",
    "                        \"target_count\": attacks[\"target_address\"].nunique(),\n",
    "                        \"attack_count\": len(attacks)\n",
    "                    })\n",
    "                \n",
    "                patterns[\"poisoning\"][\"coordinated_attacks\"] = coordinated_attacks\n",
    "    \n",
    "    return patterns\n",
    "\n",
    "# Identify attack patterns\n",
    "attack_patterns = identify_attack_patterns()\n",
    "\n",
    "print(\"\\nOverall Attack Patterns:\")\n",
    "print(f\"Dusting: {attack_patterns['dusting']['total_count']} attacks affecting {attack_patterns['dusting']['targets_affected']} addresses\")\n",
    "print(f\"Poisoning: {attack_patterns['poisoning']['total_count']} attempts affecting {attack_patterns['poisoning']['targets_affected']} addresses\")\n",
    "\n",
    "# Display common tokens used for dusting\n",
    "if \"common_tokens\" in attack_patterns[\"dusting\"]:\n",
    "    print(\"\\nCommon tokens used for dusting:\")\n",
    "    for token in attack_patterns[\"dusting\"][\"common_tokens\"][:5]:  # Show top 5\n",
    "        print(f\"- {token['mint']}: {token['count']} instances\")\n",
    "\n",
    "# Display coordinated dusting attacks\n",
    "if \"coordinated_attacks\" in attack_patterns[\"dusting\"]:\n",
    "    print(\"\\nCoordinated dusting attacks:\")\n",
    "    for attack in attack_patterns[\"dusting\"][\"coordinated_attacks\"][:3]:  # Show top 3\n",
    "        print(f\"- {attack['time']}: {attack['attack_count']} attacks targeting {attack['target_count']} addresses\")\n",
    "\n",
    "# Display reused poisoning addresses\n",
    "if \"reused_addresses\" in attack_patterns[\"poisoning\"]:\n",
    "    print(\"\\nReused poisoning addresses:\")\n",
    "    for addr in attack_patterns[\"poisoning\"][\"reused_addresses\"][:5]:  # Show top 5\n",
    "        print(f\"- {addr['address']}: used in {addr['count']} poisoning attempts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7918095",
   "metadata": {},
   "source": [
    "## Generate Recommendations\n",
    "\n",
    "Based on our analysis, let's generate recommendations for users to protect against dusting and poisoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce008d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommendations for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD:\n",
      "\n",
      "Recommendations for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH:\n",
      "\n",
      "Recommendations for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8:\n"
     ]
    }
   ],
   "source": [
    "# Generate defense recommendations\n",
    "def generate_defense_recommendations(address, dusting_data, poisoning_data):\n",
    "    recommendations = {\n",
    "        \"address\": address,\n",
    "        \"dusting_recommendations\": [],\n",
    "        \"poisoning_recommendations\": []\n",
    "    }\n",
    "    \n",
    "    # Dusting attack recommendations\n",
    "    if dusting_data and dusting_data.get(\"dust_count\", 0) > 0:\n",
    "        recommendations[\"dusting_recommendations\"] = [\n",
    "            \"Do not move dust tokens - leave them untouched to prevent address linkage\",\n",
    "            \"Consider using a dedicated wallet for receiving dust, separate from your main funds\",\n",
    "            \"Use a wallet that allows you to 'ignore' or 'hide' small token balances\"\n",
    "        ]\n",
    "        \n",
    "        # Add token-specific recommendations\n",
    "        tokens = dusting_data.get(\"dust_by_token\", [])\n",
    "        if tokens:\n",
    "            for token in tokens[:3]:  # Top 3 dusting tokens\n",
    "                recommendations[\"dusting_recommendations\"].append(\n",
    "                    f\"Be especially cautious with {token['mint']} tokens, which have been used in {token['count']} dusting attempts\"\n",
    "                )\n",
    "    \n",
    "    # Address poisoning recommendations\n",
    "    if poisoning_data and poisoning_data.get(\"poisoning_count\", 0) > 0:\n",
    "        recommendations[\"poisoning_recommendations\"] = [\n",
    "            \"Always copy and paste addresses instead of typing them manually\",\n",
    "            \"Verify the entire address, not just the beginning and end\",\n",
    "            \"Use the Solana address book feature to save trusted addresses\",\n",
    "            \"Consider using a hardware wallet with display confirmation\",\n",
    "            \"Enable transaction previews in your wallet to verify recipients\"\n",
    "        ]\n",
    "        \n",
    "        # Add specific warning about similar addresses\n",
    "        similar_addresses = poisoning_data.get(\"similar_addresses\", [])\n",
    "        if similar_addresses:\n",
    "            for i, addr in enumerate(similar_addresses[:3]):  # Top 3 similar addresses\n",
    "                recommendations[\"poisoning_recommendations\"].append(\n",
    "                    f\"Be extremely cautious with address {addr} which resembles your address\"\n",
    "                )\n",
    "    \n",
    "    return recommendations\n",
    "\n",
    "# Generate recommendations for each address\n",
    "defense_recommendations = {}\n",
    "for address in target_addresses:\n",
    "    defense_recommendations[address] = generate_defense_recommendations(\n",
    "        address,\n",
    "        dusting_analyses.get(address),\n",
    "        poisoning_analyses.get(address)\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nRecommendations for {address}:\")\n",
    "    \n",
    "    if defense_recommendations[address][\"dusting_recommendations\"]:\n",
    "        print(\"\\nDusting Attack Defense:\")\n",
    "        for i, rec in enumerate(defense_recommendations[address][\"dusting_recommendations\"], 1):\n",
    "            print(f\"{i}. {rec}\")\n",
    "    \n",
    "    if defense_recommendations[address][\"poisoning_recommendations\"]:\n",
    "        print(\"\\nAddress Poisoning Defense:\")\n",
    "        for i, rec in enumerate(defense_recommendations[address][\"poisoning_recommendations\"], 1):\n",
    "            print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedc16ed",
   "metadata": {},
   "source": [
    "## Conclusions and Report Generation\n",
    "\n",
    "Let's summarize our findings and generate a comprehensive report:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d7fa62d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Report generated and saved to ../../reports/dusting_poisoning_report_20250424_233309.md\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Dusting Attack & Address Poisoning Analysis Report\n",
       "\n",
       "Generated on: 2025-04-24 23:33:09\n",
       "\n",
       "## Addresses Analyzed\n",
       "\n",
       "- **Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD**: 0 dusting attacks, 0 poisoning attempts\n",
       "- **dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH**: 0 dusting attacks, 0 poisoning attempts\n",
       "- **AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8**: 0 dusting attacks, 0 poisoning attempts\n",
       "\n",
       "## Attack Summary\n",
       "\n",
       "- **Total Dusting Attacks**: 0\n",
       "- **Total Poisoning Attempts**: 0\n",
       "- **Addresses Affected by Dusting**: 0\n",
       "- **Addresses Affected by Poisoning**: 0\n",
       "\n",
       "\n",
       "## Detailed Analysis for Gnt27xtC473ZT2Mw5u8wZ68Z3gULkSTb5DuxJy7eJotD\n",
       "\n",
       "### Dusting Attack Analysis\n",
       "\n",
       "No dusting attacks detected.\n",
       "\n",
       "### Address Poisoning Analysis\n",
       "\n",
       "No address poisoning attempts detected.\n",
       "\n",
       "### Defense Recommendations\n",
       "\n",
       "\n",
       "## Detailed Analysis for dRiftyHA39MWEi3m9aunc5MzRF1JYuBsbn6VPcn33UH\n",
       "\n",
       "### Dusting Attack Analysis\n",
       "\n",
       "No dusting attacks detected.\n",
       "\n",
       "### Address Poisoning Analysis\n",
       "\n",
       "No address poisoning attempts detected.\n",
       "\n",
       "### Defense Recommendations\n",
       "\n",
       "\n",
       "## Detailed Analysis for AAzeEnHVAZzMNZN2xLWfSbo8RgZZ9INENT2VUE8AnX8\n",
       "\n",
       "### Dusting Attack Analysis\n",
       "\n",
       "No dusting attacks detected.\n",
       "\n",
       "### Address Poisoning Analysis\n",
       "\n",
       "No address poisoning attempts detected.\n",
       "\n",
       "### Defense Recommendations\n",
       "\n",
       "\n",
       "## General Recommendations\n",
       "\n",
       "### Dusting Attack Prevention\n",
       "\n",
       "- Use wallets that allow you to ignore or hide small token balances\n",
       "- Consider using different wallets for different purposes (cold storage, trading, etc.)\n",
       "- Monitor your wallets for unexpected token transfers\n",
       "- Be cautious when interacting with unknown tokens or airdrops\n",
       "- Consider using privacy-enhancing tools like Phantom's 'Burn Token' feature\n",
       "\n",
       "### Address Poisoning Prevention\n",
       "\n",
       "- Always copy and paste addresses, never type them manually\n",
       "- Verify the entire address, not just the beginning and end\n",
       "- Use address book features in wallets to save trusted addresses\n",
       "- Consider using a hardware wallet with visual verification\n",
       "- Use Solana Name Service (SNS) or similar domain services for frequent transactions\n",
       "- Enable transaction previews in your wallet to verify recipients\n",
       "- Double-check addresses before confirming transactions, especially high-value ones"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate summary report\n",
    "report = [\"# Dusting Attack & Address Poisoning Analysis Report\\n\"]\n",
    "report.append(f\"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "\n",
    "report.append(\"## Addresses Analyzed\\n\")\n",
    "for address in target_addresses:\n",
    "    dusting_count = dusting_analyses.get(address, {}).get(\"dust_count\", 0) if dusting_analyses.get(address) else 0\n",
    "    poisoning_count = poisoning_analyses.get(address, {}).get(\"poisoning_count\", 0) if poisoning_analyses.get(address) else 0\n",
    "    \n",
    "    report.append(f\"- **{address}**: {dusting_count} dusting attacks, {poisoning_count} poisoning attempts\")\n",
    "\n",
    "report.append(\"\\n## Attack Summary\\n\")\n",
    "report.append(f\"- **Total Dusting Attacks**: {attack_patterns['dusting']['total_count']}\")\n",
    "report.append(f\"- **Total Poisoning Attempts**: {attack_patterns['poisoning']['total_count']}\")\n",
    "report.append(f\"- **Addresses Affected by Dusting**: {attack_patterns['dusting']['targets_affected']}\")\n",
    "report.append(f\"- **Addresses Affected by Poisoning**: {attack_patterns['poisoning']['targets_affected']}\\n\")\n",
    "\n",
    "# Add common attack patterns\n",
    "if \"common_tokens\" in attack_patterns[\"dusting\"]:\n",
    "    report.append(\"### Common Dusting Tokens\\n\")\n",
    "    for token in attack_patterns[\"dusting\"][\"common_tokens\"][:5]:  # Top 5\n",
    "        report.append(f\"- **{token['mint']}**: {token['count']} instances\")\n",
    "    report.append(\"\")\n",
    "\n",
    "if \"coordinated_attacks\" in attack_patterns[\"dusting\"]:\n",
    "    report.append(\"### Coordinated Dusting Attacks\\n\")\n",
    "    for attack in attack_patterns[\"dusting\"][\"coordinated_attacks\"][:3]:  # Top 3\n",
    "        report.append(f\"- **{attack['time']}**: {attack['attack_count']} attacks targeting {attack['target_count']} addresses\")\n",
    "    report.append(\"\")\n",
    "\n",
    "if \"reused_addresses\" in attack_patterns[\"poisoning\"]:\n",
    "    report.append(\"### Common Poisoning Addresses\\n\")\n",
    "    for addr in attack_patterns[\"poisoning\"][\"reused_addresses\"][:5]:  # Top 5\n",
    "        report.append(f\"- **{addr['address']}**: used in {addr['count']} poisoning attempts\")\n",
    "    report.append(\"\")\n",
    "\n",
    "# Detailed analysis per address\n",
    "for address in target_addresses:\n",
    "    report.append(f\"\\n## Detailed Analysis for {address}\\n\")\n",
    "    \n",
    "    # Dusting analysis\n",
    "    dusting_data = dusting_analyses.get(address)\n",
    "    if dusting_data:\n",
    "        report.append(f\"### Dusting Attack Analysis\\n\")\n",
    "        report.append(f\"- **Number of attacks**: {dusting_data.get('dust_count', 0)}\")\n",
    "        \n",
    "        # Add amount statistics\n",
    "        amount_stats = dusting_data.get(\"amount_stats\", {})\n",
    "        if amount_stats:\n",
    "            report.append(f\"- **Minimum amount**: {amount_stats.get('min', 0)}\")\n",
    "            report.append(f\"- **Maximum amount**: {amount_stats.get('max', 0)}\")\n",
    "            report.append(f\"- **Average amount**: {amount_stats.get('mean', 0)}\")\n",
    "        \n",
    "        # Add temporal statistics\n",
    "        temporal_stats = dusting_data.get(\"temporal_stats\", {})\n",
    "        if temporal_stats:\n",
    "            first_dust = temporal_stats.get(\"first_dust\")\n",
    "            last_dust = temporal_stats.get(\"last_dust\")\n",
    "            is_automated = temporal_stats.get(\"is_automated\", False)\n",
    "            \n",
    "            if first_dust and last_dust:\n",
    "                report.append(f\"- **First dust**: {first_dust}\")\n",
    "                report.append(f\"- **Last dust**: {last_dust}\")\n",
    "            \n",
    "            if is_automated:\n",
    "                report.append(f\"- **Pattern**: Likely automated dusting attack (regular intervals)\")\n",
    "    else:\n",
    "        report.append(f\"### Dusting Attack Analysis\\n\")\n",
    "        report.append(\"No dusting attacks detected.\")\n",
    "    \n",
    "    # Poisoning analysis\n",
    "    poisoning_data = poisoning_analyses.get(address)\n",
    "    if poisoning_data:\n",
    "        report.append(f\"\\n### Address Poisoning Analysis\\n\")\n",
    "        report.append(f\"- **Number of attempts**: {poisoning_data.get('poisoning_count', 0)}\")\n",
    "        \n",
    "        # Add similarity statistics\n",
    "        similarity_stats = poisoning_data.get(\"similarity_stats\", {})\n",
    "        if similarity_stats:\n",
    "            report.append(f\"- **Minimum similarity**: {similarity_stats.get('min', 0):.2f}\")\n",
    "            report.append(f\"- **Maximum similarity**: {similarity_stats.get('max', 0):.2f}\")\n",
    "            report.append(f\"- **Average similarity**: {similarity_stats.get('mean', 0):.2f}\")\n",
    "        \n",
    "        # Add similar addresses\n",
    "        similar_addresses = poisoning_data.get(\"similar_addresses\", [])\n",
    "        if similar_addresses:\n",
    "            report.append(\"\\n#### Similar Addresses\\n\")\n",
    "            for i, addr in enumerate(similar_addresses[:5], 1):  # Top 5\n",
    "                report.append(f\"{i}. `{addr}`\")\n",
    "    else:\n",
    "        report.append(f\"\\n### Address Poisoning Analysis\\n\")\n",
    "        report.append(\"No address poisoning attempts detected.\")\n",
    "    \n",
    "    # Recommendations\n",
    "    recommendations = defense_recommendations.get(address, {})\n",
    "    if recommendations:\n",
    "        report.append(f\"\\n### Defense Recommendations\\n\")\n",
    "        \n",
    "        dusting_recs = recommendations.get(\"dusting_recommendations\", [])\n",
    "        if dusting_recs:\n",
    "            report.append(\"#### Dusting Attack Defense\\n\")\n",
    "            for rec in dusting_recs:\n",
    "                report.append(f\"- {rec}\")\n",
    "            report.append(\"\")\n",
    "        \n",
    "        poisoning_recs = recommendations.get(\"poisoning_recommendations\", [])\n",
    "        if poisoning_recs:\n",
    "            report.append(\"#### Address Poisoning Defense\\n\")\n",
    "            for rec in poisoning_recs:\n",
    "                report.append(f\"- {rec}\")\n",
    "\n",
    "# Add general recommendations\n",
    "report.append(\"\\n## General Recommendations\\n\")\n",
    "report.append(\"### Dusting Attack Prevention\\n\")\n",
    "report.append(\"- Use wallets that allow you to ignore or hide small token balances\")\n",
    "report.append(\"- Consider using different wallets for different purposes (cold storage, trading, etc.)\")\n",
    "report.append(\"- Monitor your wallets for unexpected token transfers\")\n",
    "report.append(\"- Be cautious when interacting with unknown tokens or airdrops\")\n",
    "report.append(\"- Consider using privacy-enhancing tools like Phantom's 'Burn Token' feature\\n\")\n",
    "\n",
    "report.append(\"### Address Poisoning Prevention\\n\")\n",
    "report.append(\"- Always copy and paste addresses, never type them manually\")\n",
    "report.append(\"- Verify the entire address, not just the beginning and end\")\n",
    "report.append(\"- Use address book features in wallets to save trusted addresses\")\n",
    "report.append(\"- Consider using a hardware wallet with visual verification\")\n",
    "report.append(\"- Use Solana Name Service (SNS) or similar domain services for frequent transactions\")\n",
    "report.append(\"- Enable transaction previews in your wallet to verify recipients\")\n",
    "report.append(\"- Double-check addresses before confirming transactions, especially high-value ones\")\n",
    "\n",
    "# Save report to file\n",
    "report_path = f\"../../reports/dusting_poisoning_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md\"\n",
    "os.makedirs(\"../../reports\", exist_ok=True)\n",
    "\n",
    "with open(report_path, \"w\") as f:\n",
    "    f.write(\"\\n\".join(report))\n",
    "\n",
    "print(f\"\\nReport generated and saved to {report_path}\")\n",
    "\n",
    "# Display report in notebook\n",
    "from IPython.display import Markdown\n",
    "display(Markdown(\"\\n\".join(report)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
